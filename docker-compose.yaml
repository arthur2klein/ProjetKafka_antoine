# Use postgres
version: '3.1'

services:

  db:
    image: postgres
    restart: always
    environment:
      POSTGRES_PASSWORD: kafkacestcool
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - backend

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - backend
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2

  kafka-broker:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka-broker
    depends_on:
      - zookeeper
    expose:
      - '9093'
    environment:
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka-broker:9093,OUTSIDE://kafka-broker:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    networks:
      - backend

  init-kafka:
    image: confluentinc/cp-kafka:7.5.3
    depends_on:
      - kafka-broker
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka-broker:9092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-broker:9092 --create --if-not-exists --topic coordinates --replication-factor 1 --partitions 1
      kafka-topics --create --topic __consumer_offsets --partitions 50 --replication-factor 1 --bootstrap-server kafka-broker:9092

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-broker:9092 --list
      "
    networks:
      - backend
    volumes:
      - ./server.properties:/etc/kafka/server.properties

  producer1:
    build:
      context: .
      dockerfile: ./Dockerfile/producer.Dockerfile
    depends_on:
      - kafka-broker
    networks:
      - backend
    environment:
      - ip=IP1

  producer2:
    build:
      context: .
      dockerfile: ./Dockerfile/producer.Dockerfile
    depends_on:
      - kafka-broker
    networks:
      - backend
    environment:
      - ip=IP2

  consumer:
    build:
      context: .
      dockerfile: ./Dockerfile/consumer.Dockerfile
    depends_on:
      - kafka-broker
      - db
    networks:
      - backend  
  
  api:
    build:
      context: .
      dockerfile: ./Dockerfile/api.Dockerfile
    ports:
      - 8000:8080
    depends_on:
      - db
    networks:
      - backend
      - frontend
  
  front:
    image: nginx
    ports:
      - 8080:80
    depends_on:
      - api
    volumes:
      - ./front.html:/usr/share/nginx/html/index.html  
    networks:
      - frontend
networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    